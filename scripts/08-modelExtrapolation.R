# model extrapolation script ----------------------------------------------

## a script `sourced` by the .Rmd to extrapolate model results.

# here, we assume that the sample of rivers are representative of the new rivers, i.e., we assume the _Conditional effects for a single typical hypothetical group_, i.e., we include new group in newdata with sample_new_levels = "uncertainty" in posterior_epred. The alternative is to assume _Conditional effects for a single brand new hypothetical group_, i.e., include new group in newdata with sample_new_levels = "gaussian" in posterior_epred.

# see Andrew-Heiss-posterior-predictions-and-average-marginal-effects-guide.pdf and brms-binomial-glmm-manual-predictions.R


# info --------------------------------------------------------------------

## use changelog
# snippet changelog

## use snippets for todos
# snippet todo-bug
# snippet todo-check-me
# snippet todo-document-me
# snippet todo-fix-me
# snippet todo-optimise-me
# snippet todo-test-me

# use snippets for code chunks
# snippet saveplot
# snippet loadlatestdata


# change log --------------------------------------------------------------

## changelog

##! CHANGE LOG: (20220907 17:51:42) Have spent considerable time writing and testing predictions. See working/jags-predictions.qmd and ../OldScripts/brms-binomial-glm-manual-predictions.R and ../OldScripts/brms-binomial-glmm-manual-predictions.R.
##! CHANGE LOG: (20220907 17:54:37) There is a difference between jags predictions and predictions generated here, and these predictions are less realistic. It could be to do with the drawing of a new RE for each new river rather than using the intercept without RE (in both mu and phi) as is done in the jags predictions, and the inclusion of a year RE that is omitted in the jags predictions.
##! CHANGE LOG: (20220908 08:45:32) I have realised by working through working/comparing-jags-and-brms-calculations.R that I was log transforming phi_lp rather than inv log (exp) transforming it: brms predictions are now tighter than those of jags, as expected, and similar when allowing for the random effects.
##! CHANGE LOG: (20221221 07:54:36) Generalised and simplified the prediction calculations


# additional libraries ----------------------------------------------------


# additional setup --------------------------------------------------------


# data --------------------------------------------------------------------

## read data
load(here("Results", "rod-exploitation-fitting-results.RData"))


# prepare the prediction data -------------------------------------------------------

## prepare prediction data
pred_dat <- validate_newdata(newdata = dat_sub_nonrse, 
                             object = best_fit, 
                             allow_new_levels = TRUE)

## add intercepts
pred_dat$Intercept <- 1 # fixef(best_fit)["Intercept", "Estimate"]
pred_dat$phi_Intercept <- 1


# get some posterior draws ------------------------------------------------

## take draws from model, default = 1000 from each chain
draws_dt <- as.data.table(as_draws_array(best_fit))


# prepare the mu part of the linear predictor -----------------------------

## names of fixed part of mu linear predictor
foo1 <- formula(best_fit)$formula[3]
foo2 <- strsplit(as.character(foo1), " \\+ ")[[1]]
fixed_mu_terms <- gsub("1", "Intercept", foo2)
fixed_mu_lp_nms <- fixed_mu_terms[!grepl("\\(Intercept \\|", fixed_mu_terms)]

## prepare the data for the fixed part of mu linear predictor
fixed_mu_lp_dat_dt <- as.data.table(pred_dat[, pmatch(fixed_mu_lp_nms, 
                                                      colnames(pred_dat)), drop = FALSE])

## adjust the column names in case of polynomials
colnames(fixed_mu_lp_dat_dt) <- gsub("raw...TRUE", "rawEQTRUE", 
                                     colnames(fixed_mu_lp_dat_dt))
colnames(fixed_mu_lp_dat_dt) <- gsub("\\.", "", 
                                     colnames(fixed_mu_lp_dat_dt))

## add "b_" to each data column name to match draws - see next
colnames(fixed_mu_lp_dat_dt) <- paste0("b_", colnames(fixed_mu_lp_dat_dt))

## prepare the draws for the fixed part of mu linear predictor
fixed_mu_lp_draws_dt <- draws_dt[variable %in% colnames(fixed_mu_lp_dat_dt), ]
foo <- dcast(fixed_mu_lp_draws_dt, ... ~ variable)
fixed_mu_lp_draws <- data.matrix(foo)[, -c(1, 2), drop = FALSE]

## ensure data are in same order as draws and compatible for multiplication
setcolorder(fixed_mu_lp_dat_dt, colnames(fixed_mu_lp_draws))
fixed_mu_lp_dat <- data.matrix(fixed_mu_lp_dat_dt)[, colnames(fixed_mu_lp_draws), 
                                                   drop = FALSE]

## calculate the fixed part of mu linear predictor
fixed_mu_lp <- lapply(1:nrow(fixed_mu_lp_dat), 
                      function(v) sweep(fixed_mu_lp_draws, 2, fixed_mu_lp_dat[v, ], "*"))

## if using Conditional effects for a single hypothetical group, either typical or brand new
if (cond_typical) {
  
  ### add in random year effect, if present
  if ("(Intercept | Year)" %in% fixed_mu_terms) {
    for (i in 1:length(fixed_mu_lp)) {
      nm <- paste0("r_Year[", pred_dat$Year[i], ",Intercept]")
      fixed_mu_lp[[i]] <- cbind(fixed_mu_lp[[i]],
                                "r_Year" = draws_dt[variable == nm, value])
    }
  }
  
  ### add in random river effect, if present, drawing a new level for each new river
  if ("(Intercept | RiverName)" %in% fixed_mu_terms) {
    for (i in 1:length(fixed_mu_lp)) {
      if (pred_dat$RiverName[i] %in% levels(dat_sub_rse$RiverName)) {
        nm <- paste0("r_RiverName[", gsub(" ", ".", pred_dat$RiverName[i]), ",Intercept]")
        fixed_mu_lp[[i]] <- cbind(fixed_mu_lp[[i]],
                                  "r_RiverName" = draws_dt[variable == nm, value])
      } else {
        d <- mean(draws_dt[variable == "sd_RiverName__Intercept", value])
        fixed_mu_lp[[i]] <- cbind(fixed_mu_lp[[i]],
                                  "r_RiverName" = rnorm(nrow(fixed_mu_lp[[i]]), 0, d))
      }
    }
  }

}
  
## make a data.table
mu_lp <- rbindlist(lapply(fixed_mu_lp, as.data.table), idcol = "Obs")

## calculate complete mu linear predictor & transform
mu_lp[, "mu_lp"] <- rowSums(mu_lp[, -1])
if (use_cauchit) {
  mu_lp[, mu := atan(mu_lp) / pi + 0.5]
} else {
  mu_lp[, mu := inv_logit_scaled(mu_lp)]
}


# prepare the phi part of the linear predictor ----------------------------

## names of fixed part of phi linear predictor
foo1 <- formula(best_fit)$pforms$phi
foo2 <- strsplit(as.character(foo1)[[3]], " \\+ ")[[1]]
fixed_phi_terms <- gsub("1", "phi_Intercept", foo2)
fixed_phi_lp_nms <- fixed_phi_terms[!grepl("\\(phi_Intercept \\|", fixed_phi_terms)]

## prepare the draws for the fixed part of phi linear predictor
fixed_phi_lp_dat_dt <- as.data.table(pred_dat[, pmatch(fixed_phi_lp_nms, 
                                                       colnames(pred_dat)), drop = FALSE])

## adjust the column names in case of polynomials
colnames(fixed_phi_lp_dat_dt) <- gsub("raw...TRUE", "rawEQTRUE", 
                                     colnames(fixed_phi_lp_dat_dt))
colnames(fixed_phi_lp_dat_dt) <- gsub("\\.", "", 
                                     colnames(fixed_phi_lp_dat_dt))

## add "b_" to each data column name to match draws - see next
colnames(fixed_phi_lp_dat_dt) <- paste0("b_", colnames(fixed_phi_lp_dat_dt))

## prepare the draws for the fixed part of phi linear predictor
fixed_phi_lp_draws_dt <- draws_dt[variable %in% colnames(fixed_phi_lp_dat_dt), ]
foo <- dcast(fixed_phi_lp_draws_dt, ... ~ variable)
fixed_phi_lp_draws <- data.matrix(foo)[, -c(1, 2), drop = FALSE]

## ensure data are in same order as draws and compatible for multiplication
setcolorder(fixed_phi_lp_dat_dt, colnames(fixed_phi_lp_draws))
fixed_phi_lp_dat <- data.matrix(fixed_phi_lp_dat_dt)[, colnames(fixed_phi_lp_draws), 
                                                     drop = FALSE]

## calculate the fixed part of phi linear predictor
fixed_phi_lp <- lapply(1:nrow(fixed_phi_lp_dat), 
                       function(v) sweep(fixed_phi_lp_draws, 2, fixed_phi_lp_dat[v, ], "*"))

## if using Conditional effects for a single hypothetical group, either typical or brand new
if (cond_typical) {
  
  ### add in random year effect, if present
  if ("(phi_Intercept | Year)" %in% fixed_phi_terms) {
    for (i in 1:length(fixed_phi_lp)) {
      nm <- paste0("r_Year__phi[", pred_dat$Year[i], ",Intercept]")
      fixed_phi_lp[[i]] <- cbind(fixed_phi_lp[[i]],
                                 "r_Year__phi" = draws_dt[variable == nm, value])
    }
  }
  
  ### add in random river effect, if present, drawing a new level for each new river
  if ("(phi_Intercept | RiverName)" %in% fixed_phi_terms) {
    for (i in 1:length(fixed_phi_lp)) {
      if (pred_dat$RiverName[i] %in% levels(dat_sub_rse$RiverName)) {
        nm <- paste0("r_RiverName__phi[", gsub(" ", ".", pred_dat$RiverName[i]), ",Intercept]")
        fixed_phi_lp[[i]] <- cbind(fixed_phi_lp[[i]],
                                   "r_RiverName__phi" = draws_dt[variable == nm, value])
      } else {
        d <- mean(draws_dt[variable == "sd_RiverName__Intercept", value])
        fixed_phi_lp[[i]] <- cbind(fixed_phi_lp[[i]],
                                   "r_RiverName__phi" = rnorm(nrow(fixed_phi_lp[[i]]), 0, d))
      }
    }
  }
  
}

## make a data.table
phi_lp <- rbindlist(lapply(fixed_phi_lp, as.data.table), idcol = "Obs")

## calculate complete phi linear predictor & transform
phi_lp[, "phi_lp"] <- rowSums(phi_lp[, -1])
phi_lp[, phi := exp(phi_lp)]


# combine mu_lp and phi_lp ------------------------------------------------

lp_dt <- cbind(mu_lp, phi_lp[, -1])


# add alpha and beta shapes -----------------------------------------------

## calculate dbeta shape parameters
lp_dt[, alpha := mu * phi]
lp_dt[, beta := (1 - mu) * phi]

## add median expectation
lp_dt[, p := qbeta(0.5, alpha, beta)]


# add catches, etc. -------------------------------------------------------

## add in catches
lp_dt$SalCatch <- rep(dat_sub_nonrse$SalCatch, each = nrow(fixed_mu_lp[[i]]))

## add in RiverName
lp_dt$RiverName <- rep(dat_sub_nonrse$RiverName, each = nrow(fixed_mu_lp[[i]]))

## add in RiverName
lp_dt$Year <- rep(dat_sub_nonrse$Year, each = nrow(fixed_mu_lp[[i]]))


# calculate N -------------------------------------------------------------

## estimate returns
lp_dt[, "N_est" := SalCatch / p]


# point estimates (and uncertainties) -------------------------------------

## uncertainty levels
prbs <- c(0.025, 0.150, 0.500, 0.850, 0.975)

## calculate means and sds
lp_dt_sum <- lp_dt[, .("exploit_est_mean" = mean(p),
                       "exploit_est_sd" = sd(p),
                       "SalCatch" = mean(SalCatch),
                       "N_est_mean" = mean(N_est),
                       "N_est_sd" = sd(N_est)),
                   by = .(RiverName, Year, Obs)]

## calculate quantiles
foo1 <- lp_dt[, as.list(quantile(p, prbs)), 
              by = .(RiverName, Year, Obs)]
foo1_nms <- paste0("exploit_", gsub("0\\.", "", sprintf(fmt = "%0.3f", prbs)))
setnames(foo1,
         old = paste0(prbs * 100, "%"), 
         new = foo1_nms)
foo2 <- lp_dt[, as.list(quantile(N_est, prbs)), 
              by = .(RiverName, Year, Obs)]
foo2_nms <- paste0("N_", gsub("0\\.", "", sprintf(fmt = "%0.3f", prbs)))
setnames(foo2, 
         old = paste0(prbs * 100, "%"), 
         new = foo2_nms)

## combine
lp_dt_sum <- cbind(lp_dt_sum, foo1[, !1:3], foo2[, !1:3])


# e&w sam outputs ---------------------------------------------------------

## produce exploit rate & adult return estimates for PSRs and E&W 
### run 26-02-2021 to generate "dummy" PFA data -> Jon Gillson -> Geir Bolstad

## actual & estimated adult returns for all PSRs since 1994 (to 2019)
psr_ests <- merge(dat_sub_rse[, .(RiverName, 
                                  Year = as.integer(as.character(Year)), 
                                  Obs = 1:nrow(dat_sub_rse), 
                                  SalCatch, 
                                  N_est_mean = RSE,
                                  exploit_est_mean = ur)], 
                  lp_dt_sum, 
                  fill = TRUE, all = TRUE)

## add Type
psr_ests[, Type := factor(ifelse(is.na(N_est_sd), "Observation", "Estimation"),
                        levels = c("Observation", "Estimation"))]

## refactorise
psr_ests$RiverName <- factor(psr_ests$RiverName, 
                             levels = sort(levels(psr_ests$RiverName)))
psr_ests$Year <- factor(psr_ests$Year)

## input mean into median where there is no estimation
psr_ests[Type == "Observation", 
         c("N_500", "exploit_500") := list(N_est_mean, exploit_est_mean)]

## reorder columns
setcolorder(psr_ests, c("RiverName", "Year", "Obs", "SalCatch",
                        "exploit_est_mean", "exploit_est_sd", foo1_nms,
                        "N_est_mean", "N_est_sd", foo2_nms))

## order by river and year
setorder(psr_ests, "RiverName", "Year")


# plot ------------------------------------------------------------------------------

## rescale y-axis labels and make pretty
formatter1000 <- function(x) { 
  return(x / 1000)
}

## plot it
ew_adult_returns_p <- ggplot(psr_ests, aes(x = Year, y = N_500, group = 1)) + 
  geom_ribbon(aes(ymin = N_025, ymax = N_975), fill = "lightgrey") +
  geom_line(aes(colour = Type)) +
  facet_wrap(~ RiverName, scales = "free_y", ncol = 8) +
  scale_y_continuous(labels = formatter1000) +
  ylab("Returns (x 1000)") +
  scale_x_discrete(breaks = as.character(c(2000, 2015))) +
  sgg(tfs = 16, lfs = 16) + 
  theme(panel.spacing = grid::unit(0, "lines"),
        axis.text.y = element_text(angle = 90, hjust = .5),
        legend.position = "top")

##! BUG: here is a bug - There are problems with Tavy and Yealm estimates - explore!


# save plots --------------------------------------------------------------

## get plot objects
p_objs <- c("ew_adult_returns_p")

## make plots in a loop
if (make_plots) {
  for (p in p_objs) {
    
    ## file name
    f_nm <- paste0("dat-", gsub("_", "-", p), "lot")
    
    ## pdf
    cairo_pdf(here("plots", paste0(f_nm, ".pdf")),
              # width = 10, height = 7)
              width = 24, height = 16)
    print(eval(as.name(p)))
    dev.off()
    
    ## jpg
    jpeg(here("plots", paste0(f_nm, ".jpg")),
         # res = 600, width = (480 * 10), height = (480 * 7))
         res = 600, width = (480 * 24), height = (480 * 16))
    print(eval(as.name(p)))
    dev.off()
    
  }
}


# save --------------------------------------------------------------------

## save returns data.table
nm <- paste0("river-estimated-returns.csv")
write.csv(psr_ests, file = here("results", nm), row.names = FALSE)

## save list
save_lst <- c(
  
  ### data objects
  "dat_sub_rse", # data for rse rivers
  "dat_sub_nonrse", # data for nonrse rivers
  "lp_dt", # prediction calculations
  "lp_dt_sum", # summary of prediction calculations
  "psr_ests", # psr estimated returns
  
  ### plots
  "ew_adult_returns_p" # estimated returns

)

## save image
if (save_it) {
  fle_nm <- paste0("rod-exploitation-extrapolation-results.RData")
  save(list = save_lst, file = here("results", fle_nm))
}
